<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://eeaic.github.io/</id><title>EEAIC</title><subtitle>EE and AI Convergence Blog</subtitle> <updated>2023-05-04T00:08:32+09:00</updated> <author> <name>Jeongkee Lim</name> <uri>https://eeaic.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://eeaic.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://eeaic.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator> <rights> © 2023 Jeongkee Lim </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>[Troubleshooting] A file name cannot contain any of the following characters</title><link href="https://eeaic.github.io/posts/Windows-filename/" rel="alternate" type="text/html" title="[Troubleshooting] A file name cannot contain any of the following characters" /><published>2023-01-25T16:45:00+09:00</published> <updated>2023-02-02T17:44:26+09:00</updated> <id>https://eeaic.github.io/posts/Windows-filename/</id> <content src="https://eeaic.github.io/posts/Windows-filename/" /> <author> <name>Jeongkee Lim</name> </author> <category term="Windows" /> <summary> Windows에서 파일을 일부 문자를 포함해서 저장하려고 시도하면 아래와 같은 이유로 저장할 수 없습니다. Figure 1: 파일 이름 입력시 사용할 수 없는 문자를 입력하면 뜨는 경고창 Troubleshooting \ / : * ? " &amp;lt; &amp;gt; |를 사용하는 것은 불가능하므로 이와 유사한 문자를 찾아 사용해야 합니다. 여기서는 두가지 방법을 소개합니다. Unicode Character Table 혹은 다른 여러 유니코드 사이트에서 사용불가 문자와 비슷한 문자를 찾을 수 있습니다. 사용불가 문자 유사한 문자 유니코드 ... </summary> </entry> <entry><title>HRDA: Context-Aware High-Resolution Domain-Adaptive Semantic Segmentation</title><link href="https://eeaic.github.io/posts/HRDA/" rel="alternate" type="text/html" title="HRDA: Context-Aware High-Resolution Domain-Adaptive Semantic Segmentation" /><published>2023-01-13T12:53:00+09:00</published> <updated>2023-01-13T12:53:00+09:00</updated> <id>https://eeaic.github.io/posts/HRDA/</id> <content src="https://eeaic.github.io/posts/HRDA/" /> <author> <name>Jeongkee Lim</name> </author> <category term="Paper Review" /> <summary> Hoyer, L., Dai, D., &amp;amp; Van Gool, L. (2022). HRDA: Context-Aware High-Resolution Domain-Adaptive Semantic Segmentation. Proceedings of the European Conference on Computer Vision (ECCV). Introduction 이 연구는 UDA에 관한 연구입니다. Target dataset에 대해 annotation을 하지 않기 위해, network는 이미 존재하거나 annotation 하기 쉬운 source dataset을 통해 훈련됩니다. 그러나, neural network은 domain shift에 매우 민감합니다. 이러한 문제는 UDA에서 source d... </summary> </entry> <entry><title>DAFormer: Improving network architectures and training strategies for domain-adaptive semantic segmentation</title><link href="https://eeaic.github.io/posts/DAFormer/" rel="alternate" type="text/html" title="DAFormer: Improving network architectures and training strategies for domain-adaptive semantic segmentation" /><published>2023-01-09T14:32:00+09:00</published> <updated>2023-01-15T18:36:14+09:00</updated> <id>https://eeaic.github.io/posts/DAFormer/</id> <content src="https://eeaic.github.io/posts/DAFormer/" /> <author> <name>Jeongkee Lim</name> </author> <category term="Paper Review" /> <summary> Hoyer, Lukas, Dengxin Dai, and Luc Van Gool. “Daformer: Improving network architectures and training strategies for domain-adaptive semantic segmentation.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022. Introduction 지난 수년간, 신경망은 많은 computer vision task에서 놀라운 성능을 달성해왔습니다. 하지만, 이러한 task에는 학습에 적합한 매우 많은 양의 data annotation이 필요합니다. Semantic segmentation... </summary> </entry> <entry><title>Sequential feature selection</title><link href="https://eeaic.github.io/posts/Sequential-feature-selection/" rel="alternate" type="text/html" title="Sequential feature selection" /><published>2022-11-15T04:22:00+09:00</published> <updated>2022-11-15T04:22:00+09:00</updated> <id>https://eeaic.github.io/posts/Sequential-feature-selection/</id> <content src="https://eeaic.github.io/posts/Sequential-feature-selection/" /> <author> <name>Jeongkee Lim</name> </author> <category term="Electronic Engeering" /> <category term="Pattern Recognition" /> <summary> Feature subset selection(FSS) Definition 특징 집합 $X=\lbrace x_i|i=1\dots N\rbrace$가 주어졌을 때, 이상적으로 $P(correct)$인 목적함수 $J(Y)$를 최대화하는 $M \lt N$인 부분집합 $Y_M$을 찾는 것 Necessary 특징을 얻기가 비싼 경우입니다. 테스트 환경에서는 많은 센서를 사용할 수 있지만, 실제 제품에는 많은 센서를 사용하지 못하는 경우가 많습니다. 분류기로부터 어떠한 의미있는 법칙을 찾을 경우입니다. 특징을 투영하게 되면, 측정된 특징의 정보가 사라지는 단점이 있습니다. 특징이 숫자가 아닐 수 있습니다. 더 적은 특징을 사용하면 모델의 파라미터... </summary> </entry> <entry><title>Linear discriminant anlaysis</title><link href="https://eeaic.github.io/posts/Linear-discriminants-analysis/" rel="alternate" type="text/html" title="Linear discriminant anlaysis" /><published>2022-11-13T01:32:00+09:00</published> <updated>2022-11-18T21:24:33+09:00</updated> <id>https://eeaic.github.io/posts/Linear-discriminants-analysis/</id> <content src="https://eeaic.github.io/posts/Linear-discriminants-analysis/" /> <author> <name>Jeongkee Lim</name> </author> <category term="Electronic Engeering" /> <category term="Pattern Recognition" /> <summary> Linear discriminant analysis, two classes 먼저, 클래스가 두 개인 경우에 한하여 생각합시다. Objective Linear discriminant analysis(LDA)는 클래스의 판별정보를 보존하면서 차원을 감소시키는 방법입니다. 먼저, 클래스 $\omega_1$에 속하는 $N_1$, $\omega_2$에 속하는 $N_2$개의 $D$-차원의 샘플 $\lbrace{x^{(1},x^{(2}, \dots x^{(N}}\rbrace$이 있다고 가정합시다. 이 샘플 $x$를 어떠한 선으로 투영시켜 스칼라 $y$를 얻습니다. \[y=w^Tx\] 이제 투영된 스칼라 $y$를 쉽게 분리할 수 있도록 투영하는 투영 벡터 $w$를 찾으면 됩니다. Figure 1: 빨간색 클... </summary> </entry> </feed>
